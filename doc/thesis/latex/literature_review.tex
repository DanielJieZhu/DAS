\section{Preliminary Literature review}

% Overview: keyword search is good for non-structured documents, it is not [as] effective with structured sources\cite{Levy96}, therefore the keyword search on relational databases approach is good then no specific APIs exist and it's there are no resources to do \textbf{a full integration} .

\subsection{Overview}

% Data Integration is about balancing between Virtual integration and data warehousing.

Since the late 1990's, several Enterprise Information Integration\footnote{%
	Enterprise Information Integration (EII) is about 'integrating data from 
	multiple sources 	\textit{without} having to to first load data into
	 a central warehouse'\cite[p.1]{eii_2005}}
 (EII) products have appeared in the market (e.g. \textit{Information Manifold} by AT\&T Lab) and an significant experience has been accumulated on: data integration formalisms, ways of describing of heterogeneous data sources and their abilities (e.g. RDBMS vs web form), query optimization (combining sources efficiently, source overlap, data quality, etc)\cite{eii_2005}. 
%
Recent research in data integration mostly focused on methods of automatic, uncertainty and feedback  driven (e.g. though statistical mediator) semi-automatic pay-as-you-go approaches\cite[ch.19]{principles_data_integration}).


The problem of keyword search over structured sources received significant attention within the last decade. Keyword search over relational, XML and other databases was explored form a number of perspectives: returning top-k ranked result tuples vs suggesting structured queries as SQL, performance optimization, user feedback mechanisms, as well as keyword searching over distributed sources. 
It is worth noting that when there is no need for 100\% result exactness keyword search combined with probabilistic schema matching allows lightweight (pay-as-you-go) data integration with minimal human effort upfront\cite[ch.16]{principles_data_integration} but could improve its quality with time by using users' feedback.

In the setting of Boolean Keyword-based Retrieval over heterogeneous sources a keyword query could be translated into a ranked list of structured queries (similarly as SODA system that propose SQL, Query Forms that propose SQL templates or Keymantic trying to achieve this without accessing the data).
In the extreme case of having no control over a web-service that do not publish its contents, techniques like Google's Deep-web crawl could index a subset of its contents enabling keyword search to some extent.

\subsection{Composing multiple data sources efficiently: Query translation using Logical Views}
The \textit{Information Manifold}\cite{Levy96} is virtual integration (EII) system that uses CARIN dialect of \textit{description logics} (could be though as simplified datalog) for queries and for source descriptions. It describes each source as logical view over the global (mediated) schema, augmented with source capabilities (e.g. what are possible and the required input parameters for a view to do selections\footnote{this makes these logical views quite similar to source APIs used by DAS, with difference that DAS currently only describe the parameters APIs and only partially the results (as an entity type)}).
%
This allows designing algorithms that could allow efficiently answering complex queries that require composing multiple the data sources by finding maximally contained rewriting of (conjunctive) input query in terms of logical views provided by sources (that is, finding an optimal way to compose the sources).

For example (based on \cite{integr_views2000}), consider such sources as expressed as views (on the left) in terms of global predicates of the mediated schema (on the right) in datalog notation:
%
{\small
\begin{verbatim}
v1(E, P, M) :- emp(E) & phone(E, P) & mgr(E, M). # employees, their phones and managers
v2(E, O, D) :- emp(E) & office(E, O) & dept(E, D). # offices and departments of employees
v3(E, P) :- emp(E) & phone(E, P) & dept(E, toy_dept). # phones of employees only in Toys dept.
\end{verbatim}
}
%
Suppose we wanted to know Sally's phone and office. We express this by datalog in global predicates:
{\small\begin{verbatim}
q1(P,O) :- phone(sally,P) & office(sally,O).
\end{verbatim}}
There are two minimal solutions (as the sources could be incomplete the full solutionis union of the two):
{\small
\begin{verbatim}
answer1(P,O) :- v1(sally,P,M) & v2(sally,O,D).
answer2(P,O) :- v3(sally,P) & v2(sally,O,D).
\end{verbatim}}
Notice that the expansions of these solutions (e.g. answer1\_exp) are not equivalent to $q_1$, but the conjunctive queries that are closest and still contained in $q_1$ (as these are the only usable views at sources):
{\footnotesize\begin{verbatim}
answer1_exp(P,O) :- emp(sally) & phone(sally,P) & mgr(sally,M) & emp(sally) & office(sally,O) & dept(sally,D).
\end{verbatim}
}
After this \textit{Information Manifold} would find an executable order that adheres the capabilities of the sources, by iteratively considering any sources whose input parameters are satisfied. 
% \subsection{Keyword search: integration on demand}
% {\color{red}TODO?: \cite[ch.16]{principles_data_integration}}


\subsection{Keyword search over a Relational Database}
The problem of Keyword search over Relational Databases (or also semi-structured sources like XML) has received a significant attention by the research community over the last decade. 

The basic approach would first build an inverted index on database tables (usually only text columns). Then after finding all occurrences of the keywords, would try to construct join paths (based on Foreign keys) that would unite tuples containing the keywords.

% In addition to many papers the PhD dissertations \cite{PhD_2011, PhD_2012} describe the approaches in details including performance optimization details (e.g. generating materialized views), etc. 
% 
A number of problem variations exist:  returning only the ranked Top-k results vs. returning ranked list of possible queries, while some systems would even allow generating more complex queries including aggregations, etc (SQAK, SODA\cite{ethz2012}).

\subsubsection*{Ranking Query Templates based on keyword query}
A simple way to access relational database could  be through a set of predefined named query templates (SQL with selection parameters or operators still to be specified) exposed to a user as a Form that the user has to fill in.

\cite{forms_kws} proposes alternative approach for processing keyword queries over relational databases: given a keyword query, instead of returning database tuples one could rank query forms that best matches the query for user to choose the right one (if they are properly named this is fairly easy). The ranking is based on checking matching of keywords to table names in templates and to column values.

An interesting feature of this approach is that a Query Template is functionally similar to any autonomous web service (which given the parameters would in turn execute that query on its database).  In case of the Data Aggregation System, a user after entering a keyword query could be provided with a ranked list of structured queries (attribute=value) that could be processed given data source constraints (e.g. parameters required) and if needed he could refine his search (e.g. provide more parameters).


\subsubsection*{Keyword query cleaning}
Keyword queries are often ambiguous, may contain misspellings or multiple keywords that refer to the same attribute value,  therefore \cite{kw_cleaning} suggested to perform query cleaning before proceeding to subsequent more computationally expensive steps (e.g. exploring all the possible join paths).

Further employing some machine learning method like HMM\cite{kw_cleaning_hmm} would allow to incorporate user's feedback (even the fact that user has chosen n-th result as a query to be executed is a good clue).


\subsubsection*{SODA: Meta-data approach}

With a goal to bridge the increasing gap between high-level (conceptual, business) and low level (physical) representations of data, researchers from \textit{ETHZ} have been investigating Generation of SQL for Business users over a very complex data warehouse at \textit{Credit Suisse}.  For converting natural language queries 
% (that in addition to keyword search could convey some semantic structure)
 into SQL statements, in addition to what used by earlier approaches they used meta-data describing the schema at both physical, conceptual and logical levels extended with DBpedia (for synonyms, etc) and domain ontologies (to capture business concepts like 'wealthy customer').
%and some natural language processing

Even on a large data-warehouse of ~220GB data with a complex schema of 400+ tables they reported that if good meta-data is available, generating even fairly complex SQL  (e.g. n-way joins with aggregations) is quite feasible for a computer. That would make it 'much easier for business users to interactively explore highly-complex data warehouses' \cite[p.932]{ethz2012}. The users also reported system's potential a) for analysing the schema and learning patterns about it and b) as tool to help documenting legacy systems.


\subsection{Keyword search over web services}


\subsubsection*{What if there is no access to index data terms}
\cite{Keymantic10, semantics_without_access} explores the case then there is no possibility to index the data terms, e.g. then a DB is behind a wrapper (e.g. accessible only through a \textit{Web form} in “Hidden Web” or \textit{a web-service}) then crawling is generally not possible.
%
In Keymantic\cite{Keymantic10} a 'keyword query is processed as follows: First, all keywords that  correspond to metadata items (e.g., field names) are extracted. The remaining
keywords are considered as possible input fields. Second, the likelihood of a remaining keyword to a metadata item is computed in order to rank different options to execute the keyword query on the
“Hidden Web” database'\cite[p.942]{ethz2012}.

\subsubsection*{Deep web search at Google}
%[multiple papers from Google] discusses various ways for implementing data integration in terms of large-scale search engine (Google): Virtual integration vs. Surfacing. They also present ways for integrating systems without human intervention through use of statistical 'mediator'.

There are two approaches to web scale search over deep-web (here Google mostly cares about web forms): \marginpar{\scriptsize\color{red}TODO: how does google use PayGo?} 
%\textit{Runtime query reformulation} - 'leaves data at the sources and routes queries to appropriate services'\cite[p. 1]{webscale_paygo} 

\textit{Deep-web surfacing} - surface deep-web (e.g. web forms) adding their results into the standard search index  easily allowing to using existing IR technology that scales well. There exist algorithms which allow to iteratively choose input parameters to the forms to surface a considerable part of the 'hidden' data without large overhead%
	\footnote{i.e. if choosing parameters in not smart way, a web form with just a couple of free inputs (or even dropdowns that's easier case), could yield as many results as a cross product of all input combinations.}.

\textit{Pay-as-you-go approach}\cite{webscale_paygo} - With this approach, 'a system starts with
very few (or inaccurate) semantic mappings and these mappings are improved over time as deemed necessary';
% TODO: cite{bootstraping}
there is NO single mediated schema over which users pose queries: queries are routed to to the relevant sources with help statistical methods that are used to model uncertainty at all levels: queries, mappings and underlying data. 

%{\color{red} TODO: Describe Keymantic\cite{Keymantic10}. This is a very suboptimal solution as indexing terms improves results (mention evaluation from SODA paper). It works only then keywords map entity names. some hybrid approaches: 
%index if exists, regexp, some string similarity measure based on historical data (e.g. even edit-distance would work for many items, like site)}




%\subsubsection*{Automatic mapping between distributed services}
%{\color{red} TODO: an interesting approach but not for CERN...}



%\subsubsection*{\color{red}Question Answering}


% See Appendix #1, for evaluation of they Demo system.



% {\color{red}There doesn't seem to be much of recent papers going towards this direction (except from specific search systems like flight fare comparisons), however these are based on structured arguments.} 

% Some other approaches could include: - creating virtual documents offline by joining tables, for instantaneous search results by employing IR techniques
% (Indexing Relational Database Content Offline for Efficient Keyword-Based Search, 2003)

% TODO: (Efficient Keyword Search Across Heterogeneous Relational Databases, 2007) : combines schema matching and structure discovery techniques to ﬁnd approximate foreign-key joins across heterogeneous databases

