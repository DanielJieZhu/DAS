#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage[margin=1.5in]{geometry}

% enable Hyperlinks
\usepackage{hyperref}
% fancy verbatim
\usepackage{fancyvrb}
\usepackage{appendix}


%This command will change the default Bibliography to References
\AtBeginDocument{
        \renewcommand{\bibname}{References}
        \renewcommand{\nomname}{List of Symbols and Abbreviations}
}


% \usepackage{minitoc}
%\renewcommand*{\toclevel@section}{1}
%\renewcommand*{\toclevel@subsection}{2}

% Redefining automatic label of Figure, Table and Eq.
\usepackage{prettyref}
\newrefformat{tab}{Table\,\ref{#1}}
\newrefformat{fig}{Figure\,\ref{#1}}
\newrefformat{eq}{Eq.\,\textup{(\ref{#1})}}

% \bibliographystyle{alpha} 
\end_preamble
\use_default_options true
\begin_modules
theorems-ams
eqs-within-sections
figs-within-sections
\end_modules
\maintain_unincluded_children false
\language british
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine natbib_authoryear
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\notefontcolor #acacac
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Keyword Search over Data Services [Early Draft]
\end_layout

\begin_layout Author
Vidmantas Zemleris
\end_layout

\begin_layout Abstract
Data integration provides a centralized solution for locating and combining
 data from multiple sources.
 The complexity of writing structured-queries is impacting not only simple
 users who are forced to learn the schema and the query language, but also
 the tech-savvy users who may have only a vague idea of where exactly to
 find the data they need.
 
\end_layout

\begin_layout Abstract
In this work we explore more intuitive alternatives such as keyword and
 natural language search, which, in fact, received fairly little attention
 in the field of data services integration.
 First, we review the state-of-the-art of approaches to searching data services
 including ways how these systems could self-adapt to users’ needs by taking
 into account historical queries and their results.
 Then, a keyword search system over enterprise data integration is presented
 that, given a keyword query, proposes top-k most probable structured queries
 which could be later answered using current data integration infrastructure.
 The system was developed and evaluated in the setting of a scientific collabora
tion of over 3,000 physicists at the CMS Experiment, CERN.

\series bold
\color red
 TODO: abstract shall be shorter: 50-100 words
\end_layout

\begin_layout Standard

\series bold
Keywords:
\series default
 Keyword-based Search; Natural-Language Search; Data Services; Enterprise
 Information Integration; Natural Language Processing
\end_layout

\begin_layout Standard

\color red
\begin_inset Newpage newpage
\end_inset


\color inherit

\begin_inset CommandInset toc
LatexCommand tableofcontents

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomencl_print
LatexCommand printnomenclature
set_width "auto"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

%
\backslash
addcontentsline{toc}{chapter}{List of Symbols and Abbreviations}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
\begin_inset Marginal
status open

\begin_layout Plain Layout

\series bold
\color red
crap! even CMS case-study version has better introduction
\end_layout

\end_inset

Enterprise Information Integration (EII
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "EII"
description "Enterprise Information Integration\\\\"

\end_inset

) provides a centralized solution for locating and combining data from multiple
 sources.
 The complexity of writing structured-queries is impacting not only simple
 users who are forced to learn the schema and the query language, but also
 the tech-savvy users who may have only a vague idea of where exactly to
 find the data they need.
 
\end_layout

\begin_layout Standard
In this work we explore more intuitive alternatives such as keyword and
 natural language search, which, in fact, received fairly little attention
 in the field of data services integration.
 First, we review the state-of-the-art of approaches to searching data services
 including ways how these systems could self-adapt to users’ needs by taking
 into account historical queries and their results.
 Then, a keyword search system over enterprise data integration is presented
 that, given a keyword query, proposes top-k most probable structured queries
 which could be later answered using current data integration infrastructure.
 The system was developed and evaluated in the setting of a scientific collabora
tion of over 3,000 physicists at the CMS
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "CMS"
description "Compact Moun Selenoid Experiment at the European Organization for Nuclear Research (CERN)"

\end_inset

 Experiment, CERN.
\end_layout

\begin_layout Standard

\series bold
\begin_inset Marginal
status collapsed

\begin_layout Plain Layout

\series bold
\color red
TODO:
\series default
 introduce the paper; add motivation: usefulness of KWS/NLs, contradicting
 results; lack of research in the field of KW/NL Search over Web Services;
 needs of CMS.
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Also some of the data may be changing often, services have limitations on
 their interfaces, and users are interested in complete and up-to-date answers
 (i.e.
 Boolean Retrieval), the problem of keyword search becomes more complex
 as it is hard or even impossible to materialize/index all the contents
 in one central place.
 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\series bold
\color red
TODO
\series default
: present the problem in general, setting at CMS and our solution
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\color red
TODO: add a motivating example in the beginning!
\end_layout

\begin_layout Standard

\color red
Major problems:
\end_layout

\begin_layout Itemize
what is better suitable for querying information: keywords, full sentence,
 or restricted structured language
\end_layout

\begin_layout Itemize
keyword search is too much ambiguous (for searching structured data)
\end_layout

\begin_layout Itemize
full sentences are long to write, and often hard to process as there are
 many ways of expressing same idea
\end_layout

\begin_layout Itemize
structured language must be learned, including schema terms and its 
\begin_inset Quotes eld
\end_inset

grammar
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Subsection
Background
\end_layout

\begin_layout Subsubsection
Intro, Usability issues
\end_layout

\begin_layout Standard
TODO: discuss differences between Structured, Keyword and NL Search
\end_layout

\begin_layout Standard
refer to Paper...
\end_layout

\begin_layout Subsubsection
Data Integration
\end_layout

\begin_layout Subsubsection
Semantic Web Services
\end_layout

\begin_layout Standard
Having detailed semantic Web Service descriptions would help interpreting
 more complex queries (in example of CMS Experiment, such as 'smallest 
\series bold
file
\series default
 in /SingleElectron/Run2011A-WElectron-*/RAW-RECO with 
\series bold
number of events
\series default
 between 100 and 1000', where 'number of events' is actually referring to
 an attribute 
\emph on
nevents
\emph default
 of a file (file.nevents).
\end_layout

\begin_layout Standard

\color magenta
Domain ontology is needed
\end_layout

\begin_layout Standard
There is a number of technologies that allow data and service providers
 to describe semantically services their services and resources, such as
 the 
\begin_inset Quotes eld
\end_inset

Simple Semantic Web Architecture and Protocol
\begin_inset Quotes erd
\end_inset

 (SSWAP) that uses third-party ontologies.
\end_layout

\begin_layout Standard
Gessler DDG, Schiltz GS, May GD, Avraham S, Town CD, Grant D, Nelson RT:
 SSWAP: A Simple Semantic Web Architecture and Protocol for semantic web
 services.
 BMC Bioinformatics 2009, 10:309.
\end_layout

\begin_layout Standard

\color magenta
In this work, we assume that the extensive service semantic descriptions
 are already existing, or are not needed, and focus on the process of translatio
n between keyword queries and the structured ones.
\end_layout

\begin_layout Standard
http://www.jbiomedsem.com/content/pdf/2041-1480-2-8.pdf
\end_layout

\begin_layout Subsection
Our work / contributions
\end_layout

\begin_layout Itemize
case analysis at the CMS Experiment
\end_layout

\begin_deeper
\begin_layout Itemize
query log analysis
\end_layout

\begin_layout Itemize
user's survey
\end_layout

\begin_layout Itemize
suggestions for data providers on how to improving the performance
\end_layout

\end_deeper
\begin_layout Itemize
literature review
\end_layout

\begin_layout Itemize
choosing a precise the topic to focus on, has took a considerable amount
 of resources
\end_layout

\begin_layout Itemize
implementation of open-source keyword search engine
\end_layout

\begin_layout Section
Problem statement
\end_layout

\begin_layout Standard
The problem in global sense is about satisfying user's information need.
 This need has to be expressed in some way, e.g.
 as natural language (NL) query, keyword (KW) query, a structured query
 or through any other interfaces such as predefined Query Forms.
\end_layout

\begin_layout Subsection
Communicating User's Intent
\end_layout

\begin_layout Standard
Deciding on what is the best suited for 
\series bold
communicating user's intent
\series default
 is a problem, where recent studies reported disagreement in their results.
 Some users prefer composing queries as complete sentences (or even natural
 speech) that is more natural 
\begin_inset CommandInset citation
LatexCommand citep
key "2011natural,ethz_kaufmann2007nl_int"

\end_inset

 than the shorter to type keyword queries that are even more ambiguous.
 Others prefer the structured languages that are 
\series bold
the easiest
\series default
 to process by a machine, but incurs a steeper learning curve (grammar and
 
\begin_inset Quotes eld
\end_inset

lexicon
\begin_inset Quotes erd
\end_inset

 has to be learned).
 
\end_layout

\begin_layout Standard

\color magenta
\begin_inset Quotes eld
\end_inset

The research suggests people prefer to state their information need rather
 than use keywords.
 § But after first using a search engine they quickly learned that full
 questions resulted in failure.
\begin_inset Quotes erd
\end_inset

 http://people.ischool.berkeley.edu/~hearst/talks/upitt.pdf
\end_layout

\begin_layout Subsection
From keywords to structured queries
\end_layout

\begin_layout Standard

\series bold
We believe that in many cases supporting a combination of these approaches
 is a good compromise: 
\series default
the input (or subset of it) that is not conforming to the rules of given
 structured language, could be processed as natural language if it conforms
 to its grammar or as a keyword query otherwise.
\end_layout

\begin_layout Standard
Given an enterprise information integration system that is able to answer
 structured queries 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
e.g.
 conjunctive queries for DAS at CERN (our main focus); SQL-like queries
 for YQL
\begin_inset CommandInset href
LatexCommand href
name "http://developer.yahoo.com/yql/"
target "http://developer.yahoo.com/yql/"

\end_inset


\end_layout

\end_inset

 and an 
\emph on
integration schema
\emph default

\begin_inset Foot
status collapsed

\begin_layout Plain Layout
consisting of entity names, their attributes, regular expressions defining
 the types of values accepted, and in some cases a list of possible input/output
 values; The integration schema is referring to data service interfaces
 (accepted inputs and outputs provided)
\end_layout

\end_inset

, we are interested in translating user's query (a list of keywords or a
 full sentence) into the corresponding structured query.

\color magenta
 The services could be also composed, but this is not yet supported by DAS
\begin_inset Marginal
status open

\begin_layout Plain Layout

\color red
composing services is of secondary importance
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
For example, a keyword query 
\begin_inset Quotes eld
\end_inset

configuration Zmm
\begin_inset Quotes erd
\end_inset

 shall be mapped into: 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
newline
\backslash
verb|config dataset=*Zmm*|
\end_layout

\end_inset


\begin_inset Foot
status collapsed

\begin_layout Plain Layout
i.e.
 configuration of datasets containing Zmm in their name; at CERN, a dataset
 is a collection of files describing physics events and meta-data about
 them
\end_layout

\end_inset

.
 While a more complex full sentence query 
\begin_inset Quotes eld
\end_inset

what are the average and total sizes of Zmm datesets containing more than
 1000 events
\begin_inset Quotes erd
\end_inset

 shall be converted into:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

{
\backslash
small
\backslash
begin{verbatim}dataset dataset=*Zmm* | grep dataset.nevents > 1000 | avg(dataset.s
ize), sum(dataset.size)
\backslash
end{verbatim}}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
More formally, an 
\emph on
\color magenta
integration schema
\emph default
\color inherit
 consists of: 
\begin_inset Marginal
status open

\begin_layout Plain Layout

\color magenta
Better terminology?
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
schema
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "schema"
description "by schema we refer to the integration schema (virtual schema based of entities exposed by the services)"

\end_inset

 vocabulary
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "schema terms"
description "entities of integration schema and their attributes"

\end_inset

: entities of 
\emph on
integration schema
\emph default
 and their attributes
\end_layout

\begin_layout Itemize
values (domain vocabulary)
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "schema values"
description "values of entity attributes (that could be input parameters of data services, or form part of their results)"

\end_inset

: values of entity attributes (that could be input parameters of data services,
 or form part of their results)
\end_layout

\begin_layout Standard
We assume a keyword query KWQ
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "KWQ"
description "keyword query\\\\"

\end_inset

 to be an ordered k-tuple of keywords 
\begin_inset Formula $\left(k_{1},k_{2},..,k_{l}\right)$
\end_inset

.
 Answering a keyword query means 
\emph on
interpreting
\emph default
 the keyword query in terms of it's semantics over the 
\emph on
\color magenta
integration schema.
 
\emph default
\color inherit
In this work, we the structured queries that we consider are 
\emph on
conjunctive queries
\emph default
 augmented with simple aggregation functions without grouping (that would
 correspond to select-project
\color magenta
-join
\color inherit
 in SQL or YQL, where selections can be only conjunctions (AND) of predicates).
\end_layout

\begin_layout Subsection

\color magenta
Something in between? A UI?
\end_layout

\begin_layout Standard
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Section
Search over Data Services 
\begin_inset Marginal
status open

\begin_layout Plain Layout
a better synonym for: Non-structured?
\end_layout

\end_inset


\end_layout

\begin_layout Standard

\color magenta
The approaches below are applicable then there is no possibility to index
 the data terms, e.g.
 then a DB is behind a wrapper (e.g.
 accessible only through a 
\emph on
Web form
\emph default
 in “Hidden Web” or a 
\emph on
web-service
\emph default
) then crawling is generally not possible.
 
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement r
overhang 1cm
width "40col%"
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vspace{-10pt}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/keymantic_workflow.png
	lyxscale 30

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vspace{-10pt}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Keyword query translation process in Keymantic (source:
\begin_inset CommandInset citation
LatexCommand citep
after "p. 1639"
key "keymantic10"

\end_inset

)
\begin_inset CommandInset label
LatexCommand label
name "fig:Keymantic-query-translation"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Keyword Search: Heuristics and exhaustive search
\end_layout

\begin_layout Standard
Taking inspiration from Keymantic 
\begin_inset CommandInset citation
LatexCommand citep
key "keymantic10"

\end_inset

 
\color magenta
(that is focusing on relational databases)
\color inherit
, a keyword query may be processed as follows (see Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Keymantic-query-translation"

\end_inset

): 
\end_layout

\begin_layout Standard
First, we use a number of similarity metrics and matching techniques
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
including lexical (edit-distance), semantic word similarity and regular
 expressions defining allowed inputs (not always informative enough) for
 generating entry points; see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Matching-keywords"

\end_inset

 for more details
\end_layout

\end_inset

 to identify the schema terms (or their values) to which each keyword may
 correspond to, along with related likelihoods (Step 1).
 Then, all keywords that correspond to meta-data items (e.g., field names)
 are extracted (Step 2).
 Third, the remaining keywords are considered as possible Value Terms (parameter
s to the input fields of web services; or value-based filters on their results).
 Then, a number of combinations (configurations) are considered and ranked,
 permuting different combinations of assignment of keywords to schema terms
 or their values.
 Each such interpretation is assigned a score based on a number of heuristics:
\end_layout

\begin_layout Itemize
promoting such combinations where nearby keywords refer to related schema
 terms (e.g.
 entity name and it's value)
\end_layout

\begin_layout Itemize
promoting such combinations that match most of the keywords; 
\end_layout

\begin_layout Itemize
if requested entity and a filter condition is the same (small increase)
\end_layout

\begin_layout Itemize

\color blue
data service constraints must be satisfied
\color inherit
: we could also include identifying interpretations that achieve high rank
 even if they do not satisfy some constraint (e.g.
 a mandatory filter is missing), and informing the user
\end_layout

\begin_layout Itemize

\series bold
boost important keywords (see Keyword Extraction, in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Keyword-extraction"

\end_inset

)!
\end_layout

\begin_layout Itemize
promote data service inputs than filters on their results: 1) it's more
 efficient, especially when this is possible; 2) there are much more of
 possible entities to filter, so the false matches are expected higher,
 while the service inputs shall cover large part of cases
\end_layout

\begin_layout Standard
Finally the configurations are interpreted into actual queries (for databases
 the join order is important; in our case (services): applying any operators
 
\color magenta
and how services are combined
\color inherit
).
 The queries could be further re-ranked by executing those of the best queries
 that are estimated to be less heavy than some threshold (based on service
 statistics, see Section 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Estimating-query-running"

\end_inset

).
\end_layout

\begin_layout Standard
Because of limited no access to the actual data, results of this method
 were reported considerably worse on queries containing data terms, even
 if all meta-data (e.g.
 business ontology) is given
\begin_inset CommandInset citation
LatexCommand citep
key "ethz2012"

\end_inset

, therefore it is helpful to have some insight on the data behind a web-service,
 but has limitations.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
% See Appendix #1, for evaluation of they Demo system.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Subsection
Keyword Search: Machine Learning
\end_layout

\begin_layout Standard
\begin_inset Wrap figure
lines 0
placement r
overhang 1cm
width "40col%"
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vspace{-60pt}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename 1000px-HMMsequence.svg.png
	lyxscale 30
	width 40text%

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
vspace{-10pt}
\end_layout

\end_inset


\begin_inset Caption

\begin_layout Plain Layout
HMM consituents
\end_layout

\end_inset


\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
Bergamaschi et al.
 approached the same problem through Hidden Markov Model (HMM
\begin_inset CommandInset nomenclature
LatexCommand nomenclature
symbol "HMM"
description "Hidden Markov Model"

\end_inset

) and allow taking into account the query logs.
 Keywords that are near to each other are expected to represent interrelated
 concepts, which motivates the application of an HMM as it can efficiently
 model such kind of interdependences 
\begin_inset CommandInset citation
LatexCommand citep
key "semantics_without_access"

\end_inset

.
 Their approach was designed for Relational Databases (then access to the
 instance is limited), but it could be also adapted for data integration
 over data services.
\end_layout

\begin_layout Standard
An HMM is a probabilistic 
\emph on
sequence labeler/classifier
\emph default
 which task is to assign a label to every unit in a sequence
\begin_inset CommandInset citation
LatexCommand citep
key "Jurafsky+Martin:2009"

\end_inset

.
 It models a stochastic process not observable directly (in our case, the
 labels are keyword correspondence to schema entities) that is observable
 only indirectly through observations produced by another stochastic process
 (keywords, in our case), assuming that the probability of a label of any
 sequence unit depend only on a fixed number of that go before it (the Markov
 Assumption).
\begin_inset Note Note
status open

\begin_layout Plain Layout
could be improved...
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In this approach, HMM is used as described below:
\end_layout

\begin_layout Itemize
keywords are represented as a sequence of 
\emph on

\begin_inset Formula $T$
\end_inset

 observations
\end_layout

\begin_deeper
\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $O=\left\{ o_{1}o_{2}...o_{T}\right\} $
\end_inset

, each from observation vocabulary 
\begin_inset Formula $V=\left\{ v_{1},...,v_{M}\right\} $
\end_inset

 
\end_layout

\end_deeper
\begin_layout Itemize
a set of
\emph on
 
\begin_inset Formula $N$
\end_inset

 states 
\emph default

\begin_inset Formula $S=\left\{ s_{1},s_{2},...,s_{N}\right\} $
\end_inset

, each representing mapping of keywords into a schema 
\series bold
term
\series default
 (entity, their attributes, operators
\begin_inset Marginal
status open

\begin_layout Plain Layout

\color magenta
operators only in DAS
\end_layout

\end_inset

).
 These are 
\begin_inset Quotes eld
\end_inset

hidden
\begin_inset Quotes erd
\end_inset

 and have to be decoded by HMM into 
\begin_inset Formula $Q=\left\{ q_{1}q_{2}...q_{T}\right\} $
\end_inset

.
\begin_inset Marginal
status open

\begin_layout Plain Layout

\series bold
\color magenta
aren't the symbols here messed up from the standard notation?
\end_layout

\end_inset


\end_layout

\begin_layout Itemize

\emph on
transition 
\emph default
probabilities, 
\begin_inset Formula $a_{ij}=P(q_{t+1}=s_{j}\mid q_{t}=s_{i})$
\end_inset

 
\end_layout

\begin_deeper
\begin_layout Itemize
use heuristics taking into account semantic relationships between database
 terms 
\color red
(aggregation, generalization, inclusion)
\end_layout

\begin_layout Itemize

\color red
Initially: with the goal to foster transition between terms belonging to
 the same table or tables connected via FK.
\end_layout

\begin_layout Itemize
Our: with the goal to foster transition between:
\end_layout

\begin_deeper
\begin_layout Itemize
terms belonging to the same entity (entity and it's attribute, attribute
 and it's value)
\end_layout

\begin_layout Itemize
terms that are commonly referred by same API call (as inputs or outputs)
\end_layout

\begin_layout Itemize
terms belonging to requested answer type 
\series bold
(not possible with HMM, but maybe possible with CRF)
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize

\emph on
emission
\emph default
 probabilities - probability of observing keyword 
\begin_inset Formula $v_{m}$
\end_inset

 from a given state (i.e.
 schema term) 
\begin_inset Formula $q_{t}$
\end_inset

: 
\begin_inset Formula $b_{i}(m)=P(o_{t}=v_{m}\mid q_{t}=s_{i})$
\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
computed on the basis of similarity measures
\end_layout

\begin_layout Itemize
edit-distance between keywords and each term (and it's 
\series bold
synonyms
\series default
) in schema vocabulary
\end_layout

\begin_layout Itemize

\color red
domain vocabulary: domain compatibilities and regular expressions
\end_layout

\begin_layout Itemize
then use calculated similarity as 
\series bold
an estimate
\series default
 for conditional probability 
\begin_inset Formula $P(q_{t}=s_{i}|o_{t}=v_{m})$
\end_inset

, then using Bayes theorem calculate emission probability is
\end_layout

\begin_layout Itemize

\series bold
\color red
are these calculated live or stored, or combination of the two !? how expensive
 would be the storage then?
\end_layout

\end_deeper
\begin_layout Itemize

\emph on
initial state
\emph default
 probabilities - in initial implementation HITS algorithm is used to estimate
 the 
\begin_inset Quotes eld
\end_inset

authority
\begin_inset Quotes erd
\end_inset

 of each entity (~how much valuable information it contains) based on number
 of attributes and links (foreign keys) to other tables 
\begin_inset CommandInset citation
LatexCommand citep
after "p.150"
key "semantics_without_access"

\end_inset

.
 
\series bold
\color red
This do not seem not so relevant without modification for data services,
 where better measures could be:
\end_layout

\begin_deeper
\begin_layout Itemize
how often an entity is accessed by users
\end_layout

\begin_layout Itemize
what's the probability that it could start a query? e.g.
 if that's 
\end_layout

\begin_layout Itemize

\series bold
TODO: what are the initial state probs defining?
\end_layout

\end_deeper
\begin_layout Standard

\series bold
\color red
\begin_inset Note Note
status open

\begin_layout Plain Layout

\series bold
\color red
TODO: how does it work? It hopefully doesn't need instantiating all schema
 terms?
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Computing answers through decoding an HMM
\end_layout

\begin_layout Standard
A List Viterbi algorithm
\begin_inset CommandInset citation
LatexCommand citep
key "list_viterbi_1994"

\end_inset

 provides a rank ordered list of top-K (globally best) candidate mappings
 of keywords into the HMM states (i.e.
 schema terms) 
\begin_inset Note Note
status open

\begin_layout Plain Layout
(in contrast to standard Viterbi returning only the most probable result)
\end_layout

\end_inset

.
 These can later be turned into structured queries (with some additional
 ambiguity to be handled).
\end_layout

\begin_layout Subsubsection*
Initialization: Setting HMM parameters
\end_layout

\begin_layout Standard
This approach could be also used even when query log is not yet available
 by estimating the HMM parameters by applying similar heuristics as in the
 earlier chapter (Heuristic based KWS).
\end_layout

\begin_layout Subsubsection*
Semi-supervised learning: incorporating users feedback
\end_layout

\begin_layout Standard

\series bold
\color magenta
TODO: this was not (?) well specified in any of their papers
\end_layout

\begin_layout Standard

\series bold
TODO: 
\series default
The standard procedures Baum-Welch algorithm...
 
\begin_inset CommandInset citation
LatexCommand citep
after "sec. 6.5. HMM training"
key "Jurafsky+Martin:2009"

\end_inset


\end_layout

\begin_layout Standard
----
\end_layout

\begin_layout Standard

\series bold
\color red
The limitation of HMM is that decision for the current label may only depend
 on a fixed number of earlier labels and input keywords, this may be true
 for keyword search, but is more complex for NL search.
\end_layout

\begin_layout Subsection

\series bold
Conditional Random Fields
\end_layout

\begin_layout Subsubsection

\series bold
notes on CRF
\end_layout

\begin_layout Standard
x input, y output
\end_layout

\begin_layout Standard
conditional likelihood of O given data x & y: L(O; y|x) ~= f(y|x; O), y
 follows x, but x itself is never unknown, so there is no need to have a
 probabilistic model of it.
\end_layout

\begin_layout Standard
conditional models do not require x and y to have the same distributions
\end_layout

\begin_layout Standard
as long as Ys do not depend on itself, it is enough that y|x, we don't have
 to worry about dependencies between Xes.
\end_layout

\begin_layout Subsubsection
[EARLY] Ideas on how our Heuristics could be mapped into CRF features could
 be mapped:
\end_layout

\begin_layout Itemize
skip word (tag - OTHER) -- penalize not matched tags 
\begin_inset Marginal
status open

\begin_layout Plain Layout
do we need a feature for that? just the transition function could have low...
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $f_{1}(s,i,l_{i},l_{i-1})$
\end_inset

=0, if 
\begin_inset Formula $l_{i}$
\end_inset

= OTHER, 0.5 otherwise (actually weights shall normalize it automatically)
\end_layout

\begin_layout Itemize
also after some words this may be prefered, e.g.:
\end_layout

\begin_deeper
\begin_layout Itemize
stopwords!
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
prefer referring to related entities:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $f_{1}(s,i,l_{i},l_{i-1})$
\end_inset

=1, if 
\begin_inset Formula $l_{i}\thickapprox l_{i-1}\mathcircumflex l_{i}\neq$
\end_inset

OTHER, 0 otherwise
\end_layout

\begin_layout Itemize
or even better multiple features:
\end_layout

\begin_deeper
\begin_layout Itemize
if X0=entity.attribute name and X=value --> 1
\end_layout

\begin_layout Itemize
if X0=entity name and X=value --> 0.8
\end_layout

\begin_layout Itemize

\series bold
how about same entity twice? multiple words could refer to the exactly same
 term (these are over-specified queries)
\end_layout

\begin_deeper
\begin_layout Itemize

\series bold
first, I must not be summed twice!)
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
this could be generalized for longer distances...
\end_layout

\end_deeper
\begin_layout Itemize
requested entity and filter condition on the same entity (small increase)
 -- this is because these are often used queries, even QL is designed such
 that PK is inferred from entity name (e.g.
 
\emph on
dataset=Zmm
\emph default
 indicates 
\emph on
dataset.name=Zmm
\emph default
)
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $f_{1}(s,i,l_{i},l_{i-1},l_{i-2},...,l_{1})$
\end_inset

=0.3, if 
\begin_inset Formula $\exists j:\, l_{j}=$
\end_inset

same entity and 
\begin_inset Formula $l_{i}$
\end_inset

is it's filter, 0 otherwise
\end_layout

\begin_layout Itemize
entity and it's primary key (primary filter) -- higher
\end_layout

\begin_layout Itemize
entity and some of it's other attributes as filter, if any -- lower...
\end_layout

\end_deeper
\begin_layout Itemize
semi-structured input, e.g.
 username=zemleris (while correct one would be user)
\end_layout

\begin_deeper
\begin_layout Itemize
either take or tokenize like this (username=, zemleris), and have to rules:
\end_layout

\begin_deeper
\begin_layout Itemize
if s[i].endswith('='), boost score for schema term
\end_layout

\begin_layout Itemize
if s[i-1].endswith('='): boost score for value especially if that's the same
 label (schema term matching is more guaranteed than of the values)
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize

\series bold
boost important keywords!
\end_layout

\begin_layout Itemize

\color magenta
a feature function to specify external features
\end_layout

\begin_deeper
\begin_layout Itemize
word similarity
\end_layout

\begin_layout Itemize

\color magenta
???could try to cheat feeding analysis results from Question Type extractor,
 E.g.
 s[0] -- expected question type.
\end_layout

\end_deeper
\begin_layout Itemize

\color magenta
finally....how about related entities (input and output) -- but these don't
 fit into linear-chain CRF
\end_layout

\begin_layout Standard
NLTK with mallets (Java) CRF: 
\begin_inset Quotes eld
\end_inset

A user-supplied feature detector function is used to convert each token
 to a featureset.
 Each feature/value pair is then encoded as a single binary feature for
 Mallet.
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
http://nltk.googlecode.com/svn/trunk/doc/api/nltk.tag.crf-module.html
\end_layout

\begin_layout Standard
feature_detector(tokens, index) -> featureset 
\end_layout

\begin_layout Subsection
Natural Language (NL) Processing and Full sentence Search
\end_layout

\begin_layout Standard
Do not try to gain complete understanding (concept of so successful Watson).
\end_layout

\begin_layout Subsubsection
Identifying if full sentences
\end_layout

\begin_layout Standard
A keyword query that is not a well-formed sentence, e.g.
 
\begin_inset Quotes eld
\end_inset

file dataset Zmm
\begin_inset Quotes erd
\end_inset

 parsed by Standford parser gives 
\begin_inset Quotes eld
\end_inset

file/VB dataset/JJ Zmm/NN
\begin_inset Quotes erd
\end_inset

, where dataset/JJ is a wrong tag.
 Applying the keyword extraction would down-rank this term without any good
 reason.
\end_layout

\begin_layout Standard
Simple approach could be checking if sentence starts with a Wh-word (what,
 where, when).
\end_layout

\begin_layout Subsubsection
Keyword extraction
\begin_inset CommandInset label
LatexCommand label
name "sub:Keyword-extraction"

\end_inset


\end_layout

\begin_layout Standard

\color red
the words extracted as 
\begin_inset Quotes eld
\end_inset

keywords
\begin_inset Quotes erd
\end_inset

 would be given higher score than others, different scores for different
 POS.
\end_layout

\begin_layout Standard

\series bold
See NLP class, slides on keyword extraction.
\end_layout

\begin_layout Standard

\series bold
\bar under
\color magenta
TODO: WE HAVE TO Evaluate each sub-approach!!!
\end_layout

\begin_layout Subsubsection
Answer Type
\end_layout

\begin_layout Itemize
Answer Type Detection - figuring out the requested Answer type
\end_layout

\begin_deeper
\begin_layout Itemize
take question headword: first NP after wh-word
\end_layout

\begin_deeper
\begin_layout Itemize
simple directly answerable by Services: where are files of Zmm located?
\end_layout

\begin_layout Itemize
complex, needs filtering: what is the total size of datasets that ....
\end_layout

\end_deeper
\begin_layout Itemize
patterns to interpret wh-words
\end_layout

\begin_deeper
\begin_layout Itemize
when --> date e.g.
 (created|modified...
 etc)
\end_layout

\begin_layout Itemize
where --> location
\end_layout

\begin_layout Itemize
how many, big/large
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsubsection
Relation extraction and Deep Parsing + Predicate Argument Structure (but
 probably no time for this)
\end_layout

\begin_layout Standard
interesting demo: http://www.nactem.ac.uk/enju/demo.html
\end_layout

\begin_layout Standard
biomedical paper works not so bad.
\end_layout

\begin_layout Standard

\bar under
\color magenta
----
\end_layout

\begin_layout Standard

\bar under
\color magenta
semantic distance, string dist WSD (word sense d..,) focus extraction (1 NP
 or last NP) 
\end_layout

\begin_layout Standard

\bar under
\color magenta
E.g.
 what is the Total size of all Zmm datasets 
\end_layout

\begin_layout Standard

\bar under
\color magenta
what is the size of /Zmm/.,X datasets --- parsing of the query file Zmm 
\end_layout

\begin_layout Standard

\bar under
\color magenta
figuring out between KWS and NL search
\end_layout

\begin_layout Subsection
Subtask: Matching keywords to entities (string matching)
\begin_inset CommandInset label
LatexCommand label
name "sub:Matching-keywords"

\end_inset


\end_layout

\begin_layout Itemize
String similarity (edit-distance)
\end_layout

\begin_deeper
\begin_layout Itemize
need to alter the weights...
\end_layout

\begin_deeper
\begin_layout Itemize
cheap removing from the end
\end_layout

\begin_layout Itemize
expensive mutations, removals from inside
\end_layout

\end_deeper
\begin_layout Itemize
matching the entity and attribute names
\end_layout

\begin_layout Itemize
values with small edit-distance (spelling-correction)
\end_layout

\end_deeper
\begin_layout Itemize
Semantic distance
\end_layout

\begin_deeper
\begin_layout Itemize
could also match the possible values
\end_layout

\end_deeper
\begin_layout Itemize
Regular expressions
\end_layout

\begin_layout Itemize
Matching keyword into an sample of values (guessing which is the best attribute
 without having all of it's values)
\end_layout

\begin_layout Subsection
Parsing Control Statements
\end_layout

\begin_layout Standard
there are quite a many ways of expressing operations (such as ordering,
 min, max, etc), and often these may look ambiguous, for instance a query
 
\begin_inset Quotes eld
\end_inset


\bar under
smallest file
\bar default
 in Zmmg with 100 or more events
\begin_inset Quotes erd
\end_inset

 is asking for 
\series bold
the smallest file
\series default
 (order by file size), but 
\series bold
not
\series default
 what is smallest file size (that would be min(file.size)).
\end_layout

\begin_layout Standard
Answer type resolving could help a little (answer type: NP: 
\begin_inset Quotes eld
\end_inset

Adj: smallest N:file
\begin_inset Quotes erd
\end_inset

), but we are still left in a quite complex situation.
\end_layout

\begin_layout Standard
Templates / Regexps
\end_layout

\begin_layout Standard
Predicate Argument Structure + Relation Extraction Rules(proLog) -- however
 too expensive given time constraints...
\end_layout

\begin_layout Subsection
Incorporating User Feedback
\end_layout

\begin_layout Itemize
influence keyword to schema term matching
\end_layout

\begin_deeper
\begin_layout Itemize
similarity metrics and their weights
\end_layout

\begin_layout Itemize
allow users to add new: [this is the explicit feedback, that is more valuable
 than implicit]
\end_layout

\begin_deeper
\begin_layout Itemize
values for schema entities
\end_layout

\begin_layout Itemize
synonyms for schema terms
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
promote/demote query suggestions
\end_layout

\begin_layout Subsubsection
Personalizing to Users' Needs
\end_layout

\begin_layout Standard
First the most common queries may be promoted in the results, maximizing
 the probability of getting results right.
\begin_inset Marginal
status open

\begin_layout Plain Layout

\color red
shall we distinguish links generated by DAS, e.g.
 for dataset: config, files, etc?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Information need among different user roles (department, function) differs
 a lot.
 At least at the CMS Experiment, CERN, users are often interested only in
 a few types of queries or entities that they are interacting with the most.
 
\end_layout

\begin_layout Standard
Prioritization may promote queries related to what the user (or his group?)
 has previously used.
\end_layout

\begin_layout Standard
\begin_inset Newpage clearpage
\end_inset


\end_layout

\begin_layout Section
A case study of the CMS Experiment at CERN
\end_layout

\begin_layout Standard
\begin_inset CommandInset include
LatexCommand input
preview true
filename "cms_case.tex"

\end_inset


\end_layout

\begin_layout Standard

\color magenta
TODO:
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Itemize
amount of data; description of services; contstraints; DAS; targeting simplifica
tion of simple-users; why new system is hard; why structured language is
 hard; powerful users vs simple users why IR is not applicable here.
 number and it’s meaning?
\end_layout

\begin_layout Itemize
feedback from Users
\end_layout

\begin_layout Itemize
consider relationships between services explicit (PK dataset.name) implicit
 - even more ambiguity and complexity
\end_layout

\begin_layout Itemize

\series bold
loose coupling of proprietary services / systems
\end_layout

\begin_layout Itemize
Current implementation / Solution developed? 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Improving the Performance
\end_layout

\begin_layout Standard

\color magenta
After initial problem analysis, it was found that most performance problems
 were due to large data amounts the data providers are processing, and some
 of the work that is unnecessarily being repeated (or requested).
 Below are the proposals:
\end_layout

\begin_layout Subsubsection*
Proposals for service providers
\end_layout

\begin_layout Standard
Pagination & Ordering
\end_layout

\begin_layout Standard
Incremental view maintenance
\end_layout

\begin_layout Standard
? Bloomjoin ?
\end_layout

\begin_layout Subsubsection*
Estimating query running time
\begin_inset CommandInset label
LatexCommand label
name "sub:Estimating-query-running"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Marginal
status open

\begin_layout Plain Layout

\color red
not yet implemented
\end_layout

\end_inset

Tracking of the execution time of each data-service, have been implemented,
 that allows a) informing user of long lasting queries, and running them
 only with his confirmation b) pre-running the speedy queries even before
 user has explicitly selected them (e.g.
 the top few queries proposed).
\end_layout

\begin_layout Standard
It has been chosen to track the mean of execution time, and it's standard
 deviation.
 Knuth has shown that the standard deviation can be efficiently computed
 in an online fashion without need to store each individual value, nor recomputi
ng everything from scratch 
\begin_inset CommandInset citation
LatexCommand citep
after "p. 232"
key "knuth1998stdev"

\end_inset

.
 
\end_layout

\begin_layout Standard
Because input parameters passed to the service may heavily impact the service
 performance, we differentiate between these parameter types: 1) some specific
 value, 2) a value with wild-card (presumably returning more results than
 specific value as it may match multiple values), 3) not provided (matches
 all values).
 So we store only four values per data-service input parameter's combination.
\end_layout

\begin_layout Subsection
Improving the Search Interface
\begin_inset Marginal
status open

\begin_layout Plain Layout

\color red
shall we put the solutions here or somewhere lower in the paper after describing
 Keyword Search?
\end_layout

\end_inset


\end_layout

\begin_layout Standard
....
\end_layout

\begin_layout Section

\color magenta
Technical Implementation details
\end_layout

\begin_layout Standard
packages, tool-kits: uncertainties, nltk, wordnet
\end_layout

\begin_layout Section
Evaluation
\end_layout

\begin_layout Standard
The evaluation was performed at the CMS Experiment described earlier.
 
\end_layout

\begin_layout Standard
......
\end_layout

\begin_layout Subsection
Usability
\end_layout

\begin_layout Subsection
Usefulness of KWS / NL / DAS QL
\end_layout

\begin_layout Itemize
KWS vs NL vs Structured language
\end_layout

\begin_layout Itemize
TODO: evaluation strategy
\end_layout

\begin_layout Section
Related work / Literature Review
\end_layout

\begin_layout Standard

\color red
TODO: plug in old and update the literature review
\end_layout

\begin_layout Subsection
DAS at CERN
\end_layout

\begin_layout Subsection
KWS based on metadata
\end_layout

\begin_layout Subsection
NL Search over Webservices
\end_layout

\begin_layout Subsection
Question Answering (QA) and Natural Language Processing
\end_layout

\begin_layout Standard
In early days of question answering these systems were conceived as natural
 language interfaces to (relational) Databases such as 
\series bold
\color magenta
[1-2]
\series default
\color inherit
.
 'These early QA systems worked by translating the natural-language question
 into a formal structured query and issuing it against a pre-compiled database
 of knowledge in order to arrive at the answer.' 
\begin_inset CommandInset citation
LatexCommand citet
key "ibm2012structured"

\end_inset

.
 There, the translation is usually based on predefined rules / templates
 representing semantic relations between concepts in the question (called
 Relation Extraction).
 Similarly more recent works also employs predefined rules for QA over Databases
\series bold
 [TODO...].
\end_layout

\begin_layout Standard
The IBM Watson that currently is a state-of-the-art open-domain QA system,
 also employs Relation Extraction, but in addition to structured sources
 it heavily relies on using text passages as an evidence for answering the
 questions (which is inevitable for answering open domain questions in a
 self-contained way).
\end_layout

\begin_layout Standard
The stages of QA that are relevant to our system includes:
\end_layout

\begin_layout Itemize
Deep Parsing
\end_layout

\begin_layout Itemize

\series bold
Predicate Argument Structure
\series default
, that normalizes and simplifies the results removing semantically irrelevant
 details such changing passive voice in active (
\begin_inset Quotes eld
\end_inset

it was bought by CERN
\begin_inset Quotes erd
\end_inset

 into 
\begin_inset Quotes eld
\end_inset

CERN bought it
\begin_inset Quotes erd
\end_inset

).
\end_layout

\begin_layout Itemize
Relation Extraction (Rule-based with handcrafted rules; or Statistical of
 lower precision)
\end_layout

\begin_layout Itemize

\color red
Keyword Extraction -- the words extracted as 
\begin_inset Quotes eld
\end_inset

keywords
\begin_inset Quotes erd
\end_inset

 would be given higher score than others
\end_layout

\begin_layout Itemize
Entity disambiguation and Matching
\end_layout

\begin_layout Standard

\end_layout

\begin_layout Standard

\series bold
TODO: QA systems over Databses that use rule-based mappings to structured
 Q
\end_layout

\begin_layout Subsection
NL S over Ontologies and Semantic Web / Semantic DBs
\end_layout

\begin_layout Subsection
KWS over Databases / Semantic KWS over large Datawarehouses + Ontology
\end_layout

\begin_layout Standard
SODA and other; SODA includes user feedback.
 Instead of trying to interpret natural language, SODA uses predefined patterns
 for more complex operations (returning top-k results, aggregation) 
\color red
as there are many ways of expressing these
\color inherit
;
\end_layout

\begin_layout Subsection
Keyword query cleaning
\end_layout

\begin_layout Subsection
Usability aspects of QA, KWS, Structured search
\end_layout

\begin_layout Subsection
User's Feedback
\end_layout

\begin_layout Standard
SODA uses Like/So So/Wrong feedback next to each result (a proposed structured
 query).
 They incorporate it by using the feedback as a component of score used
 for ranking result candidates [Add citation: SODA master thesis ethz].
 The formula used is:
\end_layout

\begin_layout Standard
.....
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citet
key "semantics_without_access"

\end_inset

proposed using an HMM, that could adapt to query logs (while the HMM parameters
 could be be 'bootstrapped' by applying a couple of heuristics even if the
 logs are unavailable).
\end_layout

\begin_layout Section
Future work
\end_layout

\begin_layout Standard
Because of the project was fairly short and the author had to follow some
 of priorities of the CMS Experiment, some parts of the research work had
 to be excluded, including: 
\series bold
\color red
TODO
\series default
.
\end_layout

\begin_layout Section
Other applications?
\end_layout

\begin_layout Section
Conclusion
\end_layout

\begin_layout Standard

\color magenta
NL and KW Search over Web Services is still lacking attention from research
 community.
\end_layout

\begin_layout Standard

\color magenta
In addition to QL this could help in learning and get results more quickly
 (immediately) proprietary systems with … rules of changing them; would
 ease adoption of Struct L and fit naturally with existing contrains.
\end_layout

\begin_layout Standard
\begin_inset Marginal
status open

\begin_layout Plain Layout

\color magenta
TODO: try to find out few cases of mapping NL to other existing services.
 (e.g.
 proprietary + public services)
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Acknowledgements
\end_layout

\begin_layout Standard
This work was financially supported by the Computing group of the Compact
 Muon Solenoid Experiment at the European Organization for Nuclear Research
 (CERN).
 The authors of this paper are thankful to Robert Gwadera and prof.
 Karl Aberer who were supervising the Master Thesis project of the first
 author at the Swiss Federal Institute of Technology in Lausanne.
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "refs"
options "bibtotoc,alpha"

\end_inset


\end_layout

\begin_layout Section*
Appendices
\end_layout

\begin_layout Standard
Appendix: Logs Analysis (thesis only?)
\end_layout

\begin_layout Standard
Appendix: Kinds of Queries at CMS
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Appendix: Proposed solutions for CMS?
\end_layout

\end_inset


\end_layout

\begin_layout Section*
TODO / Notes / etc
\end_layout

\begin_layout Standard
\begin_inset Note Greyedout
status open

\begin_layout Itemize
Showing results in natural language too!!!
\end_layout

\begin_layout Itemize
Faceted navigation and/or Refinement of User's Intent?!
\end_layout

\begin_layout Itemize
Real-time suggestions
\end_layout

\begin_layout Itemize
also Keyword Search combining services? 
\end_layout

\begin_layout Itemize
try loading the results online (but they count be different)
\end_layout

\begin_layout Itemize
understanding relationships between services (e.g.
 through existing queries?) 
\end_layout

\begin_layout Itemize
evaluation of degradation of ranking quality with expansion of search space
 (operators: aggression, min, max, post-filtering through result fields)
\end_layout

\begin_layout Itemize
Limitations of the approach: control statements? controlled statements:
 top 10, rank by, aggregate by etc
\end_layout

\begin_layout Itemize
Examples in our domain? in different domain? Evaluation/usability study
 by end-users
\end_layout

\begin_layout Itemize
\begin_inset Note Note
status collapsed

\begin_layout Itemize
interaction with the user e.g.
 creation time/ modification time dataset taken on 1/Jan/2013 dataset -
 F size, type, I n_events decrease false positives via machine learning?
 
\end_layout

\begin_layout Itemize
e.g., dateset with more than 100 event avg, sum 
\end_layout

\end_inset

 CRF implementations that can output n-best results
\end_layout

\begin_deeper
\begin_layout Itemize
http://crfpp.googlecode.com/svn/trunk/doc/index.html
\end_layout

\begin_layout Itemize
http://wapiti.limsi.fr/ 
\end_layout

\begin_layout Itemize
mallet is Java library (not prefferd because of Java)
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
\color red
\lang english
TO Check: Natural Language Querying over Databases Using Cascaded CRFs
\end_layout

\begin_layout Itemize

\lang english
Training Conditional Random Fields using Virtual Evidence Boosting 
\end_layout

\begin_deeper
\begin_layout Itemize

\lang english
http://www.ijcai.org/Past%20Proceedings/IJCAI-2007/PDF/IJCAI07-407.pdf
\end_layout

\end_deeper
\begin_layout Itemize

\series bold
About converting HMM into CRF:
\end_layout

\begin_deeper
\begin_layout Itemize
http://www.cs.ucf.edu/~gitars/cap6938/vail07conditional.pdf
\end_layout

\begin_layout Itemize

\series bold
http://knight.cis.temple.edu/~yates/cis8538/sp11/slides/conditional-random-fields.pp
t
\end_layout

\begin_deeper
\begin_layout Itemize
http://knight.cis.temple.edu/~yates/cis8538/sp11/
\end_layout

\end_deeper
\begin_layout Itemize
CRF survey:
\end_layout

\begin_deeper
\begin_layout Itemize
http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/
\end_layout

\begin_layout Itemize
http://onionesquereality.wordpress.com/2011/08/20/conditional-random-fields-a-begi
nners-survey/
\end_layout

\begin_layout Itemize
http://stackoverflow.com/questions/80089/anyone-recommend-a-good-tutorial-on-cond
itional-random-fields
\end_layout

\end_deeper
\begin_layout Itemize
in python:
\end_layout

\begin_deeper
\begin_layout Itemize
http://github.com/shuyo/iir/blob/master/sequence/crf.py
\end_layout

\begin_layout Itemize
http://blog.echen.me/2012/01/03/introduction-to-conditional-random-fields/
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
lingPIpe?
\end_layout

\begin_deeper
\begin_layout Itemize
also supports CRF: http://alias-i.com/lingpipe/demos/tutorial/crf/read-me.html
\end_layout

\end_deeper
\begin_layout Itemize
Problems with complex queries:
\end_layout

\begin_deeper
\begin_layout Itemize
give me sizes for RAW, RECO, AOD for /SingleMu/Run2012B-PromptReco-v1/RECO
 dataset and run 195529
\end_layout

\end_deeper
\begin_layout Plain Layout

\lang english
Another thing which could useful for the users at CMS Experiment, CERN,
 is search system that allows a) combing keyword-based and structured search
 (even in the same query), and that b) do not require the queries to be
 in a format that depends on physical service implementation (inputs vs
 outputs), while the current 
\emph on
DAS Query Language
\emph default
 does.
\end_layout

\end_inset


\end_layout

\end_body
\end_document
